
import argparse
import yaml
import os
from openai import OpenAI

import datetime
import json
import requests

def generate_llm_content(template_path: str, user_inputs: dict, keywords: list) -> str:
    """
    Generates content using an LLM based on a YAML template, user inputs, and keywords.

    Args:
        template_path (str): Path to the YAML template file.
        user_inputs (dict): A dictionary of user-provided inputs.
        keywords (list): A list of selected keywords.

    Returns:
        str: The content generated by the LLM.
    """
    try:
        with open(template_path, 'r') as file:
            template = yaml.safe_load(file)
    except FileNotFoundError:
        return f"Error: Template file not found at {template_path}"
    except yaml.YAMLError as e:
        return f"Error parsing YAML template: {e}"

    # Extract template guidelines and example prompt
    guidelines = template.get('guidelines', "Generate content based on the following instructions:")
    example_prompt = template.get('example_prompt', "Write a compelling piece.")
    
    # Construct the prompt for the LLM
    prompt_parts = [guidelines]
    prompt_parts.append("\n---User Inputs---")
    for key, value in user_inputs.items():
        prompt_parts.append(f"{key}: {value}")
    
    if keywords:
        prompt_parts.append("\n---Keywords---")
        prompt_parts.append(", ".join(keywords))

    prompt_parts.append(f"\n---Example Prompt for LLM---")
    prompt_parts.append(example_prompt)
    
    prompt = "\n".join(prompt_parts)

    # --- LLM INVOCATION (OpenAI GPT-3.5) ---
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        return "Error: OPENAI_API_KEY environment variable not set."

    client = OpenAI(api_key=api_key)

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",  # Using GPT-3.5 Turbo
            messages=[
                {"role": "user", "content": prompt}
            ],
            max_tokens=1024,
            temperature=0.7,
        )
        generated_content = response.choices[0].message.content
    except Exception as e:
        return f"Error during OpenAI API call: {e}"

    return generated_content

def save_content_via_api(title: str, content: str, model: str):
    api_url = "http://localhost:3000/api/content-manager" # Assuming Next.js app runs on port 3000
    headers = {'Content-Type': 'application/json'}
    payload = {
        'title': title,
        'content': content,
        'model': model,
        'timestamp': datetime.datetime.now(datetime.timezone.utc).isoformat()
    }

    try:
        response = requests.post(api_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status() # Raise an exception for HTTP errors
        print(f"Content successfully saved via API: {response.json()}")
    except requests.exceptions.RequestException as e:
        print(f"Error saving content via API: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate LLM content based on a YAML template, user inputs, and keywords.")
    parser.add_argument("--template_path", required=True, help="Path to the YAML template file.")
    parser.add_argument("--inputs", type=str, default="{}", help="JSON string of user inputs (e.g., '{\"topic\": \"AI in healthcare\"}').")
    parser.add_argument("--keywords", type=str, default="[]", help="JSON string of selected keywords (e.g., '[\"innovation\", \"future\"]').")
    parser.add_argument("--title", type=str, required=False, help="Title for the generated content to be saved via API.")

    args = parser.parse_args()

    try:
        user_inputs_dict = json.loads(args.inputs)
        keywords_list = json.loads(args.keywords)
    except json.JSONDecodeError as e:
        print(f"Error parsing JSON arguments: {e}")
        exit(1)

    output_content = generate_llm_content(args.template_path, user_inputs_dict, keywords_list)
    print("Generated Content:\n", output_content)

    if args.title and output_content and "Error:" not in output_content:
        save_content_via_api(args.title, output_content, "gpt-3.5-turbo")
